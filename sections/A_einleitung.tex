% I. Einleitung
\medskip
Diese Arbeit ist wie folgt strukturiert
\begin{itemize}
    \item In \cref{sec:mainideas} Wir stellen die Kernideen und Zielsetzung der Arbeit vor.
    \item In \cref{sec:technical-meat} Wir präsentieren die Ergebnisse und Analyse der Ergebnisse.
    \item In \cref{sec:discussion} Wir beschreiben die Implementation des Programms und technische Probleme die dabei aufgetreten sind.
\end{itemize}

\subsection{ Problemstellung }
Die Sprache Effekt befindet sich noch in der Entwicklung. Die Entwickler:innen haben den Verdacht, dass die Sprache mit der Zeit an Performance eingebüßt hat.
"Mit jeder Änderung wird Effekt ein wenig langsamer" - Philipp Schuster
Dies zu verifizieren ist nicht ohne weiteres möglich, ein in Effekt geschriebener Benchmark wird benötigt um die Performance Änderung zu quantifizieren.
Für die zukünftige Entwicklung an Effekt suchen wir eine Lösung, die es erlaubt schnell und direkt Feedback zur Performanz Änderung zu bekommen, wenn eine Änderung an Effekt vorgenommen wird.
Dabei wollen wir die Benchmarks aus dem Paper "Are We Fast Yet" verwenden.

Die Zielplattform ist dabei Linux, eine Lösung für Windows und MacOS streben wir nicht an.
Die Benchmarks sollen mindestens für das Effekt-Backend Javascript lauffähig sein.

\begin{itemize}
%   TODO: hinfaken, high level, nicht technisch
    \item Benchmarks aus Are We Fast Yet
    \item sprachen interner Performance vergleich, nicht cross-language
    \item tool für development an Effekt
    \item möglichst direkt feedback zur performance änderung an entwickler
    \item unix basiert, nicht windows
    \item ziel backend ist JS
\end{itemize}

\subsection{ Zielsetzung der Arbeit}

Um das Problem der unbekannten Performance während der Entwicklung von Effekt zu lösen, soll ein Kommandozeilen Werkzeug entwickelt werden.
Darüber können Entwickler:innen mit wenig Aufwand Benchmarks in Effekt ausführen.
Die Benchmarks sind in Effekt implementiert und basieren auf den Are-We-Fast-Yet Microbenchmarks.
Die Ausführung der Benchmarks liefert numerische Werte welche die Laufzeit der einzelnen Benchmarks beschreiben. So können die Entwickler:innnen
abschätzen ob eine Änderung an der Sprache die Performance verbessert oder verschlechtert.

Dabei wird auch untersucht, inwiefern klassische OOP Programme nach Effekt übersetzt werden können und ob Effekt stabil genug für moderat komplexe Programme ist.  
Als Zielbackends wählen wir Javascript, Chez-Lift, Chez-TODO und Chez-FIXME.
LLVM und MLTON werden nicht verwendet, da hier zu viele technische Einschränkungen vorliegen //TODO cite unfertige Backends

\subsubsection{ Forschungsfragen }
\begin{itemize}
    \item Lassen sich klassische OOP Programme übersetzen nach Effekt, und wie
    \item Wie performant sind die verschiedenen Backends von Effekt
    \item Wie nutzbar ist Effekt / Wie kaputt ist Effekt
\end{itemize}


  