% II. Technologieüberblick
Im folgenden wollen wir die verwendeten Technologien kurz besprechen.
Dabei geben wir nur einen sehr groben Überblick über die allgemeinen Punkte von Effekt und Are We Fast Yet und konzentrieren uns mehr auf die fürs uns relevanten Punkte.

\subsection{ Die Effekt Sprache  }	
Effekt ist eine research-level Programmiersprache entwickelt an der Universität Tübingen.
Die Syntax ist stark inspiriert von der Sprache \textit{Scala}.

Effekt unterscheidet sich von anderen populären Sprachen darin, dass es eine starke Kontrolle über Seiteneffekte, die Existenzdauer von Variablen und Kontrollfluss bietet.
Im Folgenden wollen wir einige Konzepte und Einschränkungen von Effekt vorstellen, welche für diese Arbeit relevant sind. Die stellt nur eine Untermenge der von Effekt bereitgestellten Funktionalität dar, für einen umfassenderen Überblick verweisen wir auf die offizielle Dokumentation der Sprache.

\subsubsection{ Effekte }

Grundsätzlich bilden Effekte ein Kernfeature der Sprache:
\begin{quote}
    Effects Generalize Exceptions\\
    Effect handlers are exception handlers on steroids! Like with exceptions, we first define the type of the exception. In Effekt, a declaration like Yield is called an effect signature.
\end{quote}

Diese ersetzen das Weitergeben von Objekten mit Methoden oder Funktionsobjekten und ermöglichen einen sehr sicheren Kontrollfluss des Programms, ohne unerwartete Seiteneffekte.
Effekte sind stark typisiert und die Sprache kann garanierten, dass keine unhandled Exceptions im Programm geworfen werden.

Im Gegensatz zu vielen anderen Sprachen, können Funktionen nicht in Variablen gespeichert werden, und nicht von Higher-Order-Funktions zurück gegeben werden. Wir können Funktionen nur von oben nach unten im Kontrollfluss weitergeben, als Parameter von aufgerufenen Funktionen, aber niemals in die andere Richtung. Funktionen und Variablen haben dabei auch eine begrenzte Lebenszeit, welche mit Abschluss des Aufrufs der Funktion endet.
Damit sind, im Gegensatz zu den Funktionsobjekten in Javascript oder den Objekten aus Java, keine Seiteneffekte auf Funktionsebene möglich und alle Funktionsaufrufe idempotent.
%//TODO verify this claim, "contextual purity"

Da Berechnungen oft zwingend ein gewisses Maß an Seiteneffekten erfordert, stellt Effekt hier eine eigene Lösung zur Verfügung.
Alternativ zu Funktionsobjekten können wir \textit{Regions} verwenden. Oberflächlich kann man sich eine Region als eine Closure vorstellen, die wir mit Variablen und Daten befüllen können und die wir als Parameter an Funktionen übergeben können, damit diese Seiteneffekt basierte Funktionalität nutzen können. Die Lifetime der Region geht dabei über den Funktionsaufruf hinaus, die Grundlage für Seiteneffekte.\\
Durch die Typisierung der Region stellt diese dem Nutzer bestimmte Funktionalität zur Verfügung, analog zu einem Interface. Die Region internen Variablen werden dabei vor dem Nutzer verborgen.

Wir nutzen konkret in dieser Arbeit Regions unter anderem für seedbasierte Zufallszahlen, dabei bildet die Region das Gegenstück zum Zufallszahlengenerator-Funktionsobjekt aus Javascript.

\begin{lstlisting}[language=JavaScript]
interface Random {
  def next(): Int
}

//Wrapper bekommt Berechnungsfunktion
//und führt diese aus, mit einer Implementation für Random
def withRandom[R]{ program: { Random } => R}: R = {
  var seed = 74755;
  def rand = new Random {
    def next() = {
    seed = mod((seed * 1309) + 13849, 100);
    seed;
    }
  }
  program{rand}
}

//Berechnung nutzt das Random interface
def sumRand(){ rand: Random }: Int = {
    rand.next() + rand.next() + rand.next()
}

//entry point für effekt
def main() = {
    val result = withRandom[Int]{ sumRand };
    println(result);
}
\end{lstlisting}

Weiter wollen wir nicht auf Effekte eingehen, da die von uns implementierten Benchmarks kaum davon Gebrauch machen.

\subsubsection{ Iteration und objektorientiertes Paradigma }

Effekt folgt stark dem Funktionalen Paradigma, objektorientierte Programmierung wird kaum unterstützt:
Klassen und Vererbung existieren nicht, nur Interfaces und Records sind verfügbar.
Bis auf Arrays sind alle Datenstrukturen der Standard Libraries immutable, auch Records sind immutable. Das bedeutet, dass alle nutzerdefinierten Datenstrukturen ebenfalls immutable sind.

Auch für uns relevant ist, dass Effekt tail-recursion erlaubt: Rekursion wobei der rekursive Aufruf den letzten Ausdruck der Funktion bildet, der Compiler dies erkennt und deshalb beim Voranschreiten der Rekursion die aufrufende Funktion nicht auf dem Stack halten muss. Die Rekursion führt also zu keinem Anwachsen des Stacks. 
Aufgrund der verfügbaren Tailrekursion hat Effekt einen starken Fokus auf Rekursion und kaum Features für Iteration. Es gibt durchaus Implementationen von Loops: each und while, diesen fehlen aber einige Quality-of-Life Features die man in anderen Sprachen findet, wie zum Beispiel break, early return oder continue.

\subsubsection{ Effekt Backend }
Effekt ist eine statisch typisierte Sprache und wird vor der Ausführung kompiliert.
Dabei können wir auswählen, welches Compiletarget bzw. Effektbackend wir verwenden wollen: Die Zielsprache, in welche wir unseren Effektcode kompilieren.
Zur Auswahl stehen:
\begin{itemize}
    \item Javascript
    \item Chez-Lift (Scheme)
    \item Chez-Monadic (Scheme)
    \item Chez-callcc (Scheme)
    \item MLTON
    \item LLVM
\end{itemize}
Dabei ist Javascript das Backend, welches am weitesten fertiggestellt und verwendbar ist. 
Zu beachten ist, dass es Unterschiede zwischen den Backends gibt.
Jedes Backend hat eine eigene Effekt-Standardlibrary, nicht immer ist eine Funktion in allen Backends implementiert, auch die konkrete Funktionalität kann je nach Sprache variieren:
So sind Arrays in Javascript dynamisch erweiterbar. Versuchen wir an eine Indexposition ausserhalb des Arrays zu schreiben, wird dieser automatisch vergrößert um das neue Element aufzunehmen.
In Mlton führt das selbe zu einem Fehler und das Programm stürzt ab.
%//TODO add code example
Auch die Signaturen von Funktionen variieren leicht, vorallem Overloads von Funktionen sind oft nicht in allen Backends in jeder Ausführung vertreten.

\subsection{ Die Are-We-Fast-Yet Benchmarks }
Um die Performanz von Effekt zu quantifizieren, benötigen wir Benchmarks, die wir ausführen und auf Zeit messen können. Die Benchmarks müssen dabei eine gewisse Aussagekraft über die allgemeine Performanz einer Sprache haben, damit wir echte Rückschlüsse ziehen können.

Für die Implementation dieser Benchmarks verwenden wir die Benchmarks aus dem Paper Are-We-Fast-Yet, im Folgenden mit AWFY abgekürzt.
Es handelt sich dabei um ein Paper von Stefan Marr, worin allgemein sprachenunabhängige Benchmarks implementiert werden, mit dem Ziel die Performance von verschiedenen Sprachen miteinander zu vergleichen.
\begin{center}
    \begin{quote}
        The goal of this project is to assess whether a language implementation is highly optimizing and thus is able to remove the overhead of programming abstractions and frameworks. We are interested in comparing language implementations with each other and optimize their compilers as well as the run-time representation of objects, closures, arrays, and strings.
    \end{quote}
\end{center}

Das Ziel dieser Benchmarks ist hier nicht in einer bestimmten Sprachen eine möglichst elegante/performante Lösung für ein Problem zu finden, oder zu testen welche Sprache die performanteste Standardlibrary hat.

Stattdessen wird postuliert, dass alle Programmiersprachen im Kern aus einigen wenigen Abstraktionen, sogenannten \textit{Core Abstractions} bestehen.  Das bedeutet, dass eine große Schnittmenge verwendeter Funktionalität in allen Sprachen besteht, welche man vergleichen kann. 


Die Grundidee ist, in einem Benchmark diese Kernabstraktionen zu nutzen, den Benchmark möglichst originalgetreu in verschiedenen Sprachen zu implementieren und dann die Laufzeit zu vergleichen. Hat Sprache A eine bessere Benchmark-Performance als Sprache B, leitet AFWY daraus ab, dass der Compiler/Interpreter von Sprache A diese Kernfeatures effektiver umsetzt als der von Sprache B.
Andere Faktoren wie Garbage Collection, Standard Libraries und Sprachspezifische Abstraktionen werden nicht untersucht.

AWFY stellt dazu folgende zwei Grundsatzregeln auf:
\begin{quote}
    1. The benchmark is `identical` for all languages.
    This is achieved by relying only on a widely available and commonly used subset of language features and data types.

    2. The benchmarks should use language `idiomatically`.
    This means, they should be realized as much as possible with idiomatic code in each language, while relying only on the core set of abstractions.
\end{quote}

\subsubsection{Macrobenchmark}
AFWY implementiert 5 Macrobenchmarks. 
Macrobenchmarks sind sehr groß, bis zu mehreren tausend Zeilen Implementation pro Macrobenchmark. Sie verwenden umfangreiche Funktionalität, haben Submodule und Imports. Als anschaulicher Vergleich ist hier ein Integration- oder End-to-End Test angebracht.

\begin{itemize}
\item CD ist eine Flugzeug Kollisions Simulation. 
\item DeltaBlue is a classic VM benchmark used to tune, e.g., Smalltalk, Java, and JavaScript VMs. It implements a constraint solver.
\item Havlak implements a loop recognition algorithm. It has been used to compare C++, Java, Go, and Scala performance.
\item Json is a JSON string parsing benchmark derived from the minimal-json Java library.
\item Richards is a classic benchmark simulating an operating system kernel. The used code is based on Wolczko's Smalltalk version.
\end{itemize}

In unserer Arbeit ignorieren wir die Macrobenchmarks aus Zeitgründen. Diese sind sehr komplex und aufwändig in der Implementation, vorallem da Effekt im Moment nur über sehr begrenzte Debugging Fähigkeiten verfügt. Auch bestehen für uns erhebliche Zweifel ob einige der Macrobenchmarks überhaupt umsetzbar sind in Effekt. So implementiert der CD-Macrobenchmark Red-Black-Trees als eine Datenstruktur um schon gesehene Flugzeuge in diesem Durchgang zu markieren, analog zu einem Hashset.
Diese Bäume sind in der Originalimplementation mutierbar, in Effekt ist das nicht möglich. Die Implementation müsste so stark verändert werden in Effekt, dass die Vergleichbarkeit kaum noch gegeben ist.

Der Aufwand die Macrobenchmarks zu implementieren ist unserer Meinung nach zu groß für zu wenig Wissensgewinn über die Performance.
Die Aussagekraft der Microbenchmarks steht in einem deutlich besseren Kosten-Nutzen Verhältnis, weshalb wir uns ausschließlich darauf konzentrieren.

\subsubsection{Microbenchmarks}
Microbenchmarks sind deutlich kleiner als Macrobenchmarks, in der Implementation im Durchschnitt 120 Zeilen. %TODO verify claim
%TODO add code examples to show idfference: macro implemtns a whole library, micro does not
Microbenchmarks konzentrieren sich dabei immer auf ein einzelnes Problem und die Lösungen kommen meist komplett ohne externe Funktionalität aus. Wir können sie uns ähnlich einem Unit Test vorstellen.
Folgende Microbenchmarks sind in AWFY implementiert, alle werden von uns in Effekt umgesetzt:
\begin{itemize}
    \item Bounce simulates a ball bouncing within a box.
    \item List recursively creates and traverses lists.
    \item Mandelbrot calculates the classic fractal. It is derived from the Computer Languages Benchmark Game.
    \item NBody simulates the movement of planets in the solar system. It is derived from the Computer Languages Benchmark Game.
    \item Permute generates permutations of an array.
    \item Queens solves the eight queens problem.
    \item Sieve finds prime numbers based on the sieve of Eratosthenes.
    \item Storage creates and verifies a tree of arrays to stress the garbage collector.
    \item Towers solves the Towers of Hanoi game.
\end{itemize}

\subsubsection{Aussagekraft der Benchmarks}
In AWFY wird argumentiert, dass die verschiedenen Benchmarks verschiedene relevante Bereiche der Berechnung abdecken, sprich bestimmte Teile der oben beschriebenen Core Abstractions.
In einem Benchmark wird die Fähigkeit zu tiefer Rekursion getestet, in einem anderen die Fähigkeit zur häufigen Belegung und Freigebung von Variablen, etc.

Die Performance aller Benchmarks soll dann Aufschluss über die Stärken und Schwächen einer Umsetzung einer Programmiersprache geben und einen Vergleich mit anderen Sprachen ermöglichen.

AFWY demonstriert anschaulich an Grafiken welche Benchmarks welche Gebiete der Core Abstractions abdecken und dass die Benchmarks sich im Ergebnis untereinander voneinander unterscheiden.

AWFY implementiert die Benchmarks in mehreren Sprachen und vergleicht die Performance dieser Sprachen miteinander. Da wir die Vergleichbarkeit mit anderen Sprachen erhalten wollen, obwohl Cross-Language-Comparison nicht der Fokus der Arbeit ist, implementieren wir die Benchmarks so originalgetreu wie möglich. 
